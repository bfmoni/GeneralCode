{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.1033287   0.48853036 -0.62057717  0.24257006 -0.67043758  3.1944188\n",
      " -0.52262582 -2.06592927  1.07878589 -0.6269742  -2.0080587   1.1079213\n",
      " -3.08111583 22.26235893]\n",
      "The model performance for training set\n",
      "--------------------------------------\n",
      "RMSE is 4.434777207504806\n",
      "\n",
      "\n",
      "The model performance for testing set\n",
      "--------------------------------------\n",
      "RMSE is 5.695484357512479\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd  \n",
    "def predict(theta,data):\n",
    "    num = data.shape[0]\n",
    "    col = data.shape[1]\n",
    "    predicts = np.zeros(num)\n",
    "    for i in range(num):\n",
    "        for j in range(col):\n",
    "            predicts[i] += theta[j] * data[i,j]\n",
    "    return predicts\n",
    "\n",
    "def gradient_descent(theta, data, answer, alpha = 0.1, n_iter = 50):\n",
    "    num = data.shape[0]\n",
    "    col = data.shape[1]\n",
    "    for iteration in range(n_iter):\n",
    "        # perform gradient descent\n",
    "        grads = np.zeros(col)\n",
    "        for i in range(num):\n",
    "            for j in range(col):\n",
    "                temp = 0 \n",
    "                for k in range(col):\n",
    "                    temp += ( theta[k] * data[i,k] ) \n",
    "                grads[j] += (temp - answer[i])  * data[i,j] / num \n",
    "        theta = theta - alpha * grads\n",
    "    return theta\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "boston_dataset = load_boston()\n",
    "boston = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)\n",
    "Y = boston_dataset.target\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# need to standardize data\n",
    "Scale = StandardScaler()\n",
    "boston = Scale.fit_transform(boston)\n",
    "#convert back to df to add intercept column\n",
    "boston = pd.DataFrame(boston, columns = ['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT'])\n",
    "boston['intercept'] = 1\n",
    "#prepare data\n",
    "data = boston.to_numpy()\n",
    "theta = np.zeros(data.shape[1])\n",
    "#split into test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test , Y_train, Y_test = train_test_split(data, Y, test_size = 0.3, random_state = 5)\n",
    "#train model\n",
    "model = gradient_descent(theta,X_train,Y_train)\n",
    "print(model)\n",
    "#test model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = (np.sqrt(mean_squared_error(Y_train, predict(model,X_train))))\n",
    "\n",
    "print(\"The model performance for training set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse))\n",
    "print(\"\\n\")\n",
    "\n",
    "# model evaluation for testing set\n",
    "rmse = (np.sqrt(mean_squared_error(Y_test, predict(model,X_test))))\n",
    "\n",
    "print(\"The model performance for testing set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49cb93f377a7abe7414b7b0f21fb3017538004a126cf690fb524202736b7fb92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
